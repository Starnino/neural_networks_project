{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Complex Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avq1oBKS3Wop"
      },
      "source": [
        "# Deep Complex Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQLo8XaIq7ES"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxSo7a_ct-8w"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.layers import Layer, Input, Flatten, Dense, Dropout, Add, BatchNormalization, Conv2D, Conv1D, ReLU, GlobalAveragePooling2D, GlobalAveragePooling1D\n",
        "from tensorflow.keras.initializers import Initializer, Constant\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, MeanSquaredError\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy, MeanAbsoluteError\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import math, os, datetime\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_6Jd3nLiEuB"
      },
      "source": [
        "## Imaginary Part Learning\n",
        "It learns the imaginary part of the real input through a single residual convolution block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5ToNh2wapCf"
      },
      "source": [
        "class ImagBlock(tf.keras.Model):\n",
        "  def __init__(self, dim, channels, filters, kernel_size, trainable=False, kernel_initializer=None, kernel_regularizer=None):\n",
        "    super(ImagBlock, self).__init__()\n",
        "    self.kernel_regularizer = kernel_regularizer\n",
        "    self.kernel_initializer = kernel_initializer\n",
        "    self.bn1 = BatchNormalization(trainable=trainable)\n",
        "    self.bn2 = BatchNormalization(trainable=trainable)\n",
        "    if dim == 2:\n",
        "      self.conv1 = Conv1D(filters=filters, kernel_size=kernel_size, padding='same', kernel_initializer=self.kernel_initializer, kernel_regularizer=self.kernel_regularizer)\n",
        "      self.conv2 = Conv1D(filters=channels, kernel_size=kernel_size, padding='same', kernel_initializer=self.kernel_initializer, kernel_regularizer=self.kernel_regularizer)\n",
        "    elif dim == 3:\n",
        "      self.conv1 = Conv2D(filters=filters, kernel_size=kernel_size, padding='same', kernel_initializer=self.kernel_initializer, kernel_regularizer=self.kernel_regularizer)\n",
        "      self.conv2 = Conv2D(filters=channels, kernel_size=kernel_size, padding='same', kernel_initializer=self.kernel_initializer, kernel_regularizer=self.kernel_regularizer)\n",
        "\n",
        "  def call(self, input):\n",
        "    x  = self.bn1(input)\n",
        "    x  = ReLU()(x)\n",
        "    x = self.conv1(x)\n",
        "    x  = self.bn2(x)\n",
        "    x  = ReLU()(x)\n",
        "    x = self.conv2(x)\n",
        "    return tf.complex(input, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_g0MEqXbtVG"
      },
      "source": [
        "input = tf.random.normal((100, 32, 32, 3))\n",
        "ImagBlock(dim=3, channels=3, filters=32, kernel_size=3)(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vcLcVHDq-1a"
      },
      "source": [
        "## Complex Batch Normalization\n",
        "Efficient normalization for complex valued inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqIQ-5HVAr4M"
      },
      "source": [
        "class ComplexBatchNorm(Layer):\n",
        "  def __init__(self, regularizer=None):\n",
        "    super(ComplexBatchNorm, self).__init__()\n",
        "    self.regularizer = regularizer\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.gamma_rr = self.add_weight('gamma_rr', shape=(1,), initializer=Constant(1/math.sqrt(2)), regularizer=self.regularizer, trainable=True)\n",
        "    self.gamma_ii = self.add_weight('gamma_ii', shape=(1,), initializer=Constant(1/math.sqrt(2)), regularizer=self.regularizer, trainable=True)\n",
        "    self.gamma_ri = self.add_weight('gamma_ri', shape=(1,), initializer=Constant(0.0), regularizer=self.regularizer, trainable=True)\n",
        "    self.beta_real = self.add_weight('beta_real', shape=(1,), initializer=Constant(0.0), regularizer=self.regularizer, trainable=True)\n",
        "    self.beta_imag = self.add_weight('beta_imag', shape=(1,), initializer=Constant(0.0), regularizer=self.regularizer, trainable=True)\n",
        "\n",
        "  def call(self, input):\n",
        "    real, imag = tf.math.real(input), tf.math.imag(input)\n",
        "    real_centered, imag_centered = real-tf.reduce_mean(real), imag-tf.reduce_mean(imag)\n",
        "    # covariances\n",
        "    cov_rr = tf.reduce_mean(real_centered*real_centered)\n",
        "    cov_ri = tf.reduce_mean(real_centered*imag_centered)\n",
        "    cov_ir = tf.reduce_mean(imag_centered*real_centered)\n",
        "    cov_ii = tf.reduce_mean(imag_centered*imag_centered)\n",
        "    # inverse square root\n",
        "    delta, tau = (cov_rr*cov_ii) - (cov_ri**2), cov_rr + cov_ii\n",
        "    s = tf.math.sqrt(delta)\n",
        "    t = tf.math.sqrt(tau + 2*s)\n",
        "    inverse_st = 1.0/(s*t)\n",
        "    inv_rr = (cov_ii + s)*inverse_st\n",
        "    inv_ii = (cov_rr + s)*inverse_st\n",
        "    inv_ri = -cov_ri*inverse_st\n",
        "    # normalization\n",
        "    real_normed = inv_rr*real_centered + inv_ri*imag_centered\n",
        "    imag_normed = inv_ri*real_centered + inv_ii*imag_centered\n",
        "    #batch normalization\n",
        "    real_bn = self.gamma_rr*real_normed + self.gamma_ri*imag_normed + self.beta_real\n",
        "    imag_bn = self.gamma_ri*real_normed + self.gamma_ii*imag_normed + self.beta_imag\n",
        "    return tf.complex(real_bn, imag_bn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZrsecmDDmQp"
      },
      "source": [
        "input = tf.complex(tf.random.normal((100, 32, 32, 3)), tf.random.normal((100, 32, 32, 3)))\n",
        "ComplexBatchNorm()(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMPa6n6brLV_"
      },
      "source": [
        "## Complex Convolutional Layer\n",
        "Implements convolution between complex inputs `W * h = (A * x - B * y) + i(B * x + A * y)`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WihJQs0hrPuk"
      },
      "source": [
        "**Complex Kernel Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmi8shC4KWDW"
      },
      "source": [
        "class ComplexConvInitialization(Initializer):\n",
        "  def __init__(self, unit, input_size):\n",
        "    super(ComplexConvInitialization, self).__init__()\n",
        "    self.unit = unit\n",
        "    self.input_size = float(input_size)\n",
        "\n",
        "  def __call__(self, shape, dtype=None):\n",
        "    scale = 1/(tf.sqrt(self.input_size))\n",
        "    magnitude = tfp.random.rayleigh(shape=shape, scale=scale)\n",
        "    phase = tf.random.uniform(shape=shape, minval=-math.pi, maxval=math.pi)\n",
        "    comp_weights = tf.complex(magnitude, 0.0)*tf.math.exp(tf.complex(0.0, 1.0)*tf.complex(phase, 0.0))\n",
        "    return tf.math.real(comp_weights) if self.unit == 'real' else tf.math.imag(comp_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCTsohBWrVo2"
      },
      "source": [
        "**Convolutional Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKolQFd533Dl"
      },
      "source": [
        "class ComplexConv(Layer):\n",
        "  def __init__(self, filters, kernel_size, strides=None, kernel_regularizer=None):\n",
        "    super(ComplexConv, self).__init__()\n",
        "    self.filters = filters\n",
        "    self.kernel_size = kernel_size\n",
        "    self.strides = strides\n",
        "    self.kernel_regularizer = kernel_regularizer\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    if len(input_shape) == 4:\n",
        "      kernel_shape = (self.kernel_size, self.kernel_size, input_shape[-1], self.filters)\n",
        "    elif len(input_shape) == 3:\n",
        "      kernel_shape = (self.kernel_size, input_shape[-1], self.filters)\n",
        "\n",
        "    self.real_kernel = self.add_weight('real_kernel', shape=kernel_shape, initializer=ComplexConvInitialization('real', input_shape[1]), regularizer=self.kernel_regularizer, trainable=True)\n",
        "    self.imag_kernel = self.add_weight('imag_kernel', shape=kernel_shape, initializer=ComplexConvInitialization('imag', input_shape[1]), regularizer=self.kernel_regularizer, trainable=True)\n",
        "\n",
        "  def call(self, input):\n",
        "    real = tf.math.real(input)\n",
        "    imag = tf.math.imag(input)\n",
        "    if len(input.shape) == 4:\n",
        "      real_conv = tf.nn.conv2d(real, filters=self.real_kernel, padding='SAME', strides=self.strides) - tf.nn.conv2d(imag, filters=self.imag_kernel, padding='SAME', strides=self.strides)\n",
        "      imag_conv = tf.nn.conv2d(real, filters=self.imag_kernel, padding='SAME', strides=self.strides) + tf.nn.conv2d(imag, filters=self.real_kernel, padding='SAME', strides=self.strides)\n",
        "    elif len(input.shape) == 3:\n",
        "      real_conv = tf.nn.conv1d(real, filters=self.real_kernel, padding='SAME', stride=self.strides) - tf.nn.conv1d(imag, filters=self.imag_kernel, padding='SAME', stride=self.strides)\n",
        "      imag_conv = tf.nn.conv1d(real, filters=self.imag_kernel, padding='SAME', stride=self.strides) + tf.nn.conv1d(imag, filters=self.real_kernel, padding='SAME', stride=self.strides)\n",
        "    return tf.complex(real_conv, imag_conv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78S8V720UC4t"
      },
      "source": [
        "input = tf.complex(tf.random.normal((10, 32, 32, 3)), tf.random.normal((10, 32, 32, 3)))\n",
        "ComplexConv(filters=64, kernel_size=3)(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKKAOaEDrmT_"
      },
      "source": [
        "## Complex Relu\n",
        "Complex valued activation functions\n",
        "**cRelu, zRelu, modRelu**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEM7jaH3FFjW"
      },
      "source": [
        "class CRelu(Layer):\n",
        "  def __init__(self):\n",
        "    super(CRelu, self).__init__()\n",
        "\n",
        "  def call(self, input):\n",
        "    return tf.complex(tf.nn.relu(tf.math.real(input)), tf.nn.relu(tf.math.imag(input)))\n",
        "\n",
        "\n",
        "class ZRelu(Layer):\n",
        "  def __init__(self):\n",
        "    super(ZRelu, self).__init__()\n",
        "  \n",
        "  def call(self, input):\n",
        "    inf = tf.zeros_like(input, dtype='float32')\n",
        "    sup = tf.ones_like(input, dtype='float32')*math.pi/2 \n",
        "    return tf.where(tf.math.logical_and(tf.math.angle(input) >= inf, tf.math.angle(input) <= sup), input, tf.zeros_like(input))\n",
        "\n",
        "\n",
        "class ModRelu(Layer):\n",
        "  def __init__(self, regularizer=None):\n",
        "    super(ModRelu, self).__init__()\n",
        "    self.regularizer = regularizer\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.b = self.add_weight('b', shape=input_shape[1:], initializer=Constant(0.5), regularizer=self.regularizer, trainable=True)\n",
        "  \n",
        "  def call(self, input):\n",
        "    biased_abs = tf.abs(input) - self.b\n",
        "    relu = tf.nn.relu(biased_abs)\n",
        "    ang = tf.math.angle(input)\n",
        "    return tf.complex(biased_abs*tf.math.cos(ang), biased_abs*tf.math.sin(ang))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYJdqWRrKD9g"
      },
      "source": [
        "input = tf.constant([[0-0.5j, 0.5+0j], [1+2j, 2+1j]],dtype='complex64')\n",
        "CRelu()(input)\n",
        "#ZRelu()(input)\n",
        "#ModRelu()(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vuk36XGTgerO"
      },
      "source": [
        "**Complex Dropout**\n",
        "\n",
        "Dropout real ad imaginary part of complex inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VNYYxkka-Nu"
      },
      "source": [
        "class ComplexDropout(Layer):\n",
        "  def __init__(self, rate):\n",
        "    super(ComplexDropout, self).__init__()\n",
        "    self.rate = rate\n",
        "\n",
        "  def call(self, input):\n",
        "    real = tf.math.real(input)\n",
        "    imag = tf.math.imag(input)\n",
        "    real_drop = Dropout(self.rate)(real)\n",
        "    imag_drop = Dropout(self.rate)(imag)\n",
        "    return tf.complex(real_drop, imag_drop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNIku2zkED8l"
      },
      "source": [
        "input = tf.complex(tf.random.normal((10, 32, 32, 3)), tf.random.normal((10, 32, 32, 3)))\n",
        "ComplexDropout(0.4)(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98JSP00Eruqv"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq--k49WZkbM"
      },
      "source": [
        "### Image Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzXovjaM3bCE"
      },
      "source": [
        "**Real Valued Residual Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20j_3_UG3Z4v"
      },
      "source": [
        "class Resnet():\n",
        "  def __init__(self, blocks, filters, output_units):\n",
        "    super(Resnet, self).__init__()\n",
        "    self.filters = filters\n",
        "    self.blocks = blocks\n",
        "    self.output_units = output_units\n",
        "    self.model = self.build()\n",
        "\n",
        "  def build(self):\n",
        "    inputs = Input(shape=(32,32,3))\n",
        "    x = Conv2D(filters=self.filters[0], kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x  = BatchNormalization()(x)\n",
        "    b = ReLU()(x)\n",
        "\n",
        "    for i in range(len(self.filters)):\n",
        "      for _ in range(self.blocks):  \n",
        "        x  = BatchNormalization()(b)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(filters=self.filters[i], kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "        x  = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv2D(filters=self.filters[i], kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        b = Add()([x, b])\n",
        "\n",
        "      if i != len(self.filters)-1:\n",
        "        b = Conv2D(filters=self.filters[i+1], kernel_size=1, strides=2, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(b)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(b)\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(self.output_units, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    return tf.keras.Model(inputs=[inputs], outputs=[outputs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jZqXJOF3gTx"
      },
      "source": [
        "**Complex Valued Residual Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVCCJOaFaPX7"
      },
      "source": [
        "class ComplexResNet():\n",
        "  def __init__(self, blocks, filters, output_units):\n",
        "    super(ComplexResNet, self).__init__()\n",
        "    self.blocks = blocks\n",
        "    self.filters = filters\n",
        "    self.output_units = output_units\n",
        "    self.model = self.build()\n",
        "\n",
        "  def build(self):\n",
        "    inputs = Input(shape=(32,32,3))\n",
        "    x = ImagBlock(dim=3, channels=3, filters=10, kernel_size=3, trainable=True, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = ComplexConv(filters=self.filters[0], kernel_size=7, kernel_regularizer=l2(1e-4))(x)\n",
        "    x = ComplexBatchNorm(regularizer=l2(1e-4))(x)\n",
        "    b = CRelu()(x)\n",
        "\n",
        "    for i in range(len(self.filters)):\n",
        "      for _ in range(self.blocks):\n",
        "        x = ComplexBatchNorm(regularizer=l2(1e-4))(b)\n",
        "        x = CRelu()(x)\n",
        "        x = ComplexConv(filters=self.filters[i], kernel_size=3, kernel_regularizer=l2(1e-4))(x)\n",
        "        x = ComplexBatchNorm(regularizer=l2(1e-4))(x)\n",
        "        x = CRelu()(x)\n",
        "        x = ComplexConv(filters=self.filters[i], kernel_size=3, kernel_regularizer=l2(1e-4))(x)\n",
        "        x = ComplexDropout(0.4)(x)\n",
        "        b = Add()([x, b])\n",
        "      \n",
        "      if i != len(self.filters)-1:\n",
        "        b = ComplexConv(filters=self.filters[i+1], kernel_size=1, strides=2, kernel_regularizer=l2(1e-4))(b)\n",
        "    \n",
        "    x = GlobalAveragePooling2D()(b)\n",
        "    x = Flatten()(x)  \n",
        "    outputs = Dense(self.output_units, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    return tf.keras.Model(inputs=[inputs], outputs=[outputs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5mhYR8EZkbO"
      },
      "source": [
        "### Time Series Forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2e_lrc8ZsuS"
      },
      "source": [
        "**Real Valued Residual Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XnaOWqPZtS9"
      },
      "source": [
        "class Resnet():\n",
        "  def __init__(self, blocks, filters, output_units):\n",
        "    super(Resnet, self).__init__()\n",
        "    self.blocks = blocks\n",
        "    self.filters = filters\n",
        "    self.output_units = output_units\n",
        "    self.model = self.build()\n",
        "\n",
        "  def build(self):\n",
        "    inputs = Input(shape=(24,19))\n",
        "    x = Conv1D(filters=self.filters[0], kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x  = BatchNormalization()(x)\n",
        "    b = ReLU()(x)\n",
        "\n",
        "    for i in range(len(self.filters)):\n",
        "      for _ in range(self.blocks):  \n",
        "        x  = BatchNormalization()(b)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv1D(filters=self.filters[i], kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "        x  = BatchNormalization()(x)\n",
        "        x = ReLU()(x)\n",
        "        x = Conv1D(filters=self.filters[i], kernel_size=3, padding='same', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "        x = Dropout(0.4)(x)\n",
        "        b = Add()([x, b])\n",
        "\n",
        "      if i != len(self.filters)-1:\n",
        "        b = Conv1D(filters=self.filters[i+1], kernel_size=1, strides=2, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(b)\n",
        "\n",
        "    x = GlobalAveragePooling1D()(b)\n",
        "    x = Dense(2048, activation='relu', kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    outputs = Dense(self.output_units, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    return tf.keras.Model(inputs=[inputs], outputs=[outputs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZn3Nj9MZsuT"
      },
      "source": [
        "**Complex Valued Residual Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmZ6qdKbZt5w"
      },
      "source": [
        "class ComplexResNet():\n",
        "  def __init__(self, blocks, filters, output_units):\n",
        "    super(ComplexResNet, self).__init__()\n",
        "    self.blocks = blocks\n",
        "    self.filters = filters\n",
        "    self.output_units = output_units\n",
        "    self.model = self.build()\n",
        "\n",
        "  def build(self):\n",
        "    inputs = Input(shape=(24,19))\n",
        "    x = ImagBlock(dim=2, channels=19, filters=10, kernel_size=3, trainable=True, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = ComplexConv(filters=self.filters[0], kernel_size=7, kernel_regularizer=l2(1e-4))(x)\n",
        "    x = ComplexBatchNorm(regularizer=l2(1e-4))(x)\n",
        "    b = ModRelu(regularizer=l2(1e-4))(x)\n",
        "\n",
        "    for i in range(len(self.filters)):\n",
        "      for _ in range(self.blocks):\n",
        "        x = ComplexBatchNorm(regularizer=l2(1e-4))(b)\n",
        "        x = ModRelu(regularizer=l2(1e-4))(x)\n",
        "        x = ComplexConv(filters=self.filters[i], kernel_size=3, kernel_regularizer=l2(1e-4))(x)\n",
        "        x = ComplexBatchNorm(regularizer=l2(1e-4))(x)\n",
        "        x = ModRelu(regularizer=l2(1e-4))(x)\n",
        "        x = ComplexConv(filters=self.filters[i], kernel_size=3, kernel_regularizer=l2(1e-4))(x)\n",
        "        x = ComplexDropout(0.4)(x)\n",
        "        b = Add()([x, b])\n",
        "      \n",
        "      if i != len(self.filters)-1:\n",
        "        b = ComplexConv(filters=self.filters[i+1], kernel_size=1, strides=2, kernel_regularizer=l2(1e-4))(b)\n",
        "    \n",
        "    x = GlobalAveragePooling1D()(b)\n",
        "    x = Dense(2048, activation=ModRelu(regularizer=l2(1e-4)), kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    outputs = Dense(self.output_units, kernel_initializer='he_normal', kernel_regularizer=l2(1e-4))(x)\n",
        "    return tf.keras.Model(inputs=[inputs], outputs=[outputs])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc6cP_LJK8r-"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2X3QvX-LBF1"
      },
      "source": [
        "### CIFAR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEuunn2i5rOQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da1c367e-4f5e-41ad-cb43-879910deaf74"
      },
      "source": [
        "(train_images, y_train), (test_images, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "#(train_images, y_train), (test_images, y_test) = tf.keras.datasets.cifar100.load_data()\n",
        "x_train, x_test = train_images/255.0, test_images/255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0MrhMZKMRq7"
      },
      "source": [
        "### WEATHER\n",
        "\n",
        "[Weather time series dataset](https://www.bgc-jena.mpg.de/wetter/) recorded by the Max Planck Institute for Biogeochemistry"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP3gd3gMMOdI"
      },
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)\n",
        "df = pd.read_csv(csv_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgf1GFU2Wgu5"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGxe1nqpT3XZ"
      },
      "source": [
        "#take 10 minutes intervals to 1h intervals\n",
        "df = df[5::6]\n",
        "\n",
        "# change erroneous measures\n",
        "wv = df['wv (m/s)']\n",
        "bad_wv = wv == -9999.0\n",
        "wv[bad_wv] = 0.0\n",
        "\n",
        "max_wv = df['max. wv (m/s)']\n",
        "bad_max_wv = max_wv == -9999.0\n",
        "max_wv[bad_max_wv] = 0.0\n",
        "\n",
        "# change wind velocity to vector\n",
        "wv = df.pop('wv (m/s)')\n",
        "max_wv = df.pop('max. wv (m/s)')\n",
        "\n",
        "# Convert to radians.\n",
        "wd_rad = df.pop('wd (deg)')*np.pi / 180\n",
        "\n",
        "# Calculate the wind x and y components.\n",
        "df['Wx'] = wv*np.cos(wd_rad)\n",
        "df['Wy'] = wv*np.sin(wd_rad)\n",
        "\n",
        "# Calculate the max wind x and y components.\n",
        "df['max Wx'] = max_wv*np.cos(wd_rad)\n",
        "df['max Wy'] = max_wv*np.sin(wd_rad)\n",
        "\n",
        "# Calculate time signals \n",
        "date_time = pd.to_datetime(df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
        "timestamp_s = date_time.map(datetime.datetime.timestamp)\n",
        "\n",
        "day = 24*60*60\n",
        "year = (365.2425)*day\n",
        "\n",
        "df['Day sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
        "df['Day cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
        "df['Year sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
        "df['Year cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-w6p4SYW_JV"
      },
      "source": [
        "**Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcq1iO-5Vvoq"
      },
      "source": [
        "n = len(df)\n",
        "train_df = df[0:int(n*0.7)]\n",
        "val_df = df[int(n*0.7):int(n*0.9)]\n",
        "test_df = df[int(n*0.9):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAb1DHc1XSsg"
      },
      "source": [
        "**Normalize Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzljvyiFXSQ4"
      },
      "source": [
        "train_mean = train_df.mean()\n",
        "train_std = train_df.std()\n",
        "\n",
        "train_df = (train_df - train_mean) / train_std\n",
        "val_df = (val_df - train_mean) / train_std\n",
        "test_df = (test_df - train_mean) / train_std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8N_AOlmXcVO"
      },
      "source": [
        "**Data Windowing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRTrjw4FasAP"
      },
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, train_df, val_df, test_df, input_width, label_width, shift, batch_size=32, label_columns=None):\n",
        "    \n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "    self.batch_size = batch_size\n",
        "    self.label_columns = label_columns\n",
        "    \n",
        "    self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
        "    self.total_window_size = input_width + shift\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
        "\n",
        "  def split_window(self, features):\n",
        "    inputs = features[:, self.input_slice, :]\n",
        "    labels = features[:, self.labels_slice, :]\n",
        "    if self.label_columns is not None:\n",
        "      labels = tf.stack([labels[:, :, self.column_indices[name]] for name in self.label_columns], axis=-1)\n",
        "\n",
        "    inputs.set_shape([None, self.input_width, None])\n",
        "    labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "    return inputs, labels\n",
        "\n",
        "  def make_dataset(self, data):\n",
        "    data = np.array(data, dtype=np.float32)\n",
        "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
        "        data=data,\n",
        "        targets=None,\n",
        "        sequence_length=self.total_window_size,\n",
        "        sequence_stride=1,\n",
        "        shuffle=True,\n",
        "        batch_size=self.batch_size)\n",
        "\n",
        "    ds = ds.map(self.split_window)\n",
        "\n",
        "    return ds\n",
        "\n",
        "  @property\n",
        "  def train(self):\n",
        "    return self.make_dataset(self.train_df)\n",
        "\n",
        "  @property\n",
        "  def val(self):\n",
        "    return self.make_dataset(self.val_df)\n",
        "\n",
        "  @property\n",
        "  def test(self):\n",
        "    return self.make_dataset(self.test_df)\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km5LrziB9eMy"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlrbngxFkeN9"
      },
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch == 10: return lr*10\n",
        "  elif epoch == 100: return lr/10\n",
        "  elif epoch == 120: return lr/10\n",
        "  elif epoch == 150: return lr/10\n",
        "  else: return lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c4CJDoAWaju"
      },
      "source": [
        "### Image Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBnDfV0FqZfc"
      },
      "source": [
        "resnet = Resnet(blocks=16, filters=[16, 32, 64], output_units=10).model\n",
        "#resnet = ComplexResNet(blocks=14, filters=[12, 24, 48], output_units=10).model\n",
        "resnet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8p4NwvJ7ZrQ"
      },
      "source": [
        "resnet.compile( \n",
        "    optimizer=SGD(learning_rate=0.01, momentum=0.9, nesterov=True, clipnorm=1.0),\n",
        "    loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[SparseCategoricalAccuracy()]\n",
        ")\n",
        "print('MODEL TRAINING')\n",
        "history = resnet.fit(x_train, y_train, epochs=60, batch_size=128, validation_split=0.3, shuffle=True, callbacks=LearningRateScheduler(scheduler))\n",
        "print('\\nMODEL EVALUATION')\n",
        "_, accuracy = resnet.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb08znnnWajw"
      },
      "source": [
        "### Time Series Forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeknyBL8Vj0J"
      },
      "source": [
        "**Single-step (1h) and Multi-step (24h) Windows**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMJZlYj9VkAF"
      },
      "source": [
        "single_step_window = WindowGenerator(\n",
        "    train_df, val_df, test_df, \n",
        "    input_width=24, label_width=1, shift=1, \n",
        "    batch_size=128, label_columns=['T (degC)'])\n",
        "\n",
        "multi_step_window = WindowGenerator(\n",
        "    train_df, val_df, test_df, \n",
        "    input_width=24, label_width=24, shift=1,\n",
        "    batch_size=128, label_columns=['T (degC)'])\n",
        "\n",
        "train = single_step_window.train\n",
        "valid = single_step_window.val\n",
        "test = single_step_window.test\n",
        "#train = multi_step_window.train\n",
        "#valid = multi_step_window.val\n",
        "#test = multi_step_window.test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEYBB-2CWoLE"
      },
      "source": [
        "resnet = Resnet(blocks=16, filters=[16, 32, 64], output_units=1).model\n",
        "#resnet = ComplexResNet(blocks=14, filters=[12, 24, 48], output_units=1).model\n",
        "resnet.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpcGyGfOWjPp"
      },
      "source": [
        "resnet.compile( \n",
        "    optimizer=Adam(clipnorm=1.0),\n",
        "    loss=MeanSquaredError(),\n",
        "    metrics=[MeanAbsoluteError()]\n",
        ")\n",
        "print('MODEL TRAINING')\n",
        "history = resnet.fit(train, validation_data=valid, epochs=10)\n",
        "print('\\nMODEL EVALUATION')\n",
        "_, accuracy = resnet.evaluate(test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}